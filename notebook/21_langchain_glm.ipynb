{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce3e4a0-de45-4e96-b17a-240c8e19486c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install langchain -i https://pypi.douban.com/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a36b9e-a06a-454c-8eb1-acc5f288c3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface.model import HuggingFacePredictor\n",
    "\n",
    "predictor = HuggingFacePredictor(\n",
    "    endpoint_name='CHATGLM2-6B-INT4-20231204-030044'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6229450d-d81e-416c-9bc7-2d76c6ce24c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_NAME = predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09f87d-a12b-441a-afba-72e4c24c54f4",
   "metadata": {},
   "source": [
    "# Official Guide\n",
    "\n",
    "https://python.langchain.com/docs/integrations/llms/sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628d16bb-b408-4f78-8fe6-35d17954fbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "example_doc_1 = \"\"\"\n",
    "Peter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital.\n",
    "Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well.\n",
    "Therefore, Peter stayed with her at the hospital for 3 days without leaving.\n",
    "\"\"\"\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=example_doc_1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efaf33a-ee6f-41cf-8c11-103386fcb85b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "query = \"\"\"How long was Elizabeth hospitalized?\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33a0b67f-a2b4-4f4a-b61d-e562b01c0068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({prompt: prompt, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        # return response_json[0][\"generated_text\"]\n",
    "        return response_json\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c79f214-c56a-4f19-95f7-7b68aee42107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \"{'outputs': 'Elizabeth was hospitalized for 3 days.\\\\n\\\\n\\\\n','source': 'Peter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital. Since she was diagnosed with a brain injury, the doctor told Peter to stay Besides her until she gets well. Therefore, Peter stayed with her at the hospital for 3 days without leaving.\\\\n\\\\n\\\\n','suggested_answer': 'Elizabeth was hospitalized for 3 days.\\\\n\\\\n\\\\n'}\"}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_chain(\n",
    "    llm=SagemakerEndpoint(\n",
    "         endpoint_name=endpoint_name, \n",
    "         region_name=region, \n",
    "         model_kwargs={\"max_new_tokens\": 700, \"top_p\": 0.9, \"temperature\": 0.6},\n",
    "         endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "         content_handler=content_handler\n",
    "     ),\n",
    "    prompt=PROMPT,\n",
    ")\n",
    "\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff488d-7da4-43a6-a496-1f84a92c1f60",
   "metadata": {},
   "source": [
    "## Medium\n",
    "\n",
    "https://medium.com/@ryanlempka/fundamentals-of-combining-langchain-and-sagemaker-with-a-llama-2-example-694924ab0d92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30ebdb8f-54a9-4219-827f-e4c3a02f06a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current region is: cn-northwest-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "session = boto3.session.Session()\n",
    "REGION = session.region_name\n",
    "print(\"The current region is:\", region)\n",
    "\n",
    "ENDPOINT_NAME = predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69bc42af-273b-4ed8-975c-41138af80f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "import os\n",
    "import json\n",
    "\n",
    "region = REGION\n",
    "endpoint_name = ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05410393-cf84-4929-85ce-fc1baa0ecfe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\" : [[{\"role\" : \"system\",\n",
    "        \"content\" : \"You are a kind robot.\"},\n",
    "        {\"role\" : \"user\", \"content\" : prompt}]],\n",
    "        \"parameters\" : {**model_kwargs}})\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        # return response_json[0][\"generation\"][\"content\"]\n",
    "        return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "415e8165-e4f9-4a24-a931-78131766cc34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"{content}\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05ac89b8-a460-4c33-ab05-8f4482c3012f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "llm=SagemakerEndpoint(\n",
    "     endpoint_name=endpoint_name, \n",
    "     region_name=region, \n",
    "     # model_kwargs={\"max_new_tokens\": 700, \"top_p\": 0.9, \"temperature\": 0.6},\n",
    "     # endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "     content_handler=content_handler\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2c8bc05-eaa1-4654-ae8d-bf8a8b1033ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "     llm=llm,\n",
    "     prompt=prompt\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8bbb67d-c857-4f22-908d-284e357f1b94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the content of the input for the user role is not defined in the provided information. Could you please provide the content for the user role?\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run({\"How can I travel from New York to Los Angeles?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba075ec8-4d7a-4c6f-8bf8-5d26ad08c6b6",
   "metadata": {},
   "source": [
    "## K\n",
    "\n",
    "https://github.com/kyopark2014/LLM-LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54658e42-9c78-41eb-8172-2adf6be35fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({'inputs': prompt, 'parameters': model_kwargs})\n",
    "        return input_str.encode('utf-8')\n",
    "      \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))        \n",
    "        # return response_json[0][\"generated_text\"]\n",
    "        return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1c6b448-8b76-4da3-aed6-b6a9f9fc391c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = ENDPOINT_NAME\n",
    "aws_region = boto3.Session().region_name\n",
    "parameters = {\n",
    "    \"max_new_tokens\": 300\n",
    "}\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name = endpoint_name, \n",
    "    region_name = aws_region, \n",
    "    model_kwargs = parameters,\n",
    "    content_handler = content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9faf0c77-1bc0-4c43-b16d-3e40ede8a025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"Tell me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341dced-689a-441e-b3f9-1b1cdf9ab8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
