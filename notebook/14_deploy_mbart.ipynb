{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bead0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt -U -i https://pypi.douban.com/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c7240a-5883-4ecd-be2c-4a402ef9cacb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install protobuf==3.20.* -i https://pypi.douban.com/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6972a1c3-f801-4d01-8371-3e79ccde4c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=\"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead30966-cb5e-48a0-ae2a-2bba6acac58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4854d8-7736-44e2-9271-162f55fd4105",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26635620-66d2-4a0d-92dc-bc15e24cd041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44207987-7730-4d9c-8896-cfec2d5e7356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e01894b-e10b-4703-aafd-494ee008818d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the air conditioner is on, the flight resumes too quickly, especially in winter when the weather is cold. If the air conditioner is not on, the flight resumes faster as soon as the weather is cold\n"
     ]
    }
   ],
   "source": [
    "sentence = \"开空调的情况下，续航掉的太快了，特别是冬天天气冷的时候，不开空调不行，天气一冻，续航就掉的更快\"\n",
    "\n",
    "tokenizer.src_lang = 'zh_CN'\n",
    "tokenizer.tgt_lang = 'en_XX'\n",
    "\n",
    "encoded = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "model = model.to(device)\n",
    "generated_tokens = model.generate(**encoded)\n",
    "decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c4668-2ae2-4334-bbb1-c002b907a589",
   "metadata": {},
   "source": [
    "## Deploy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110483e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = dict()\n",
    "\n",
    "config[\"S3_MODEL\"] = \"s3://hugging-face/llm/mbart.tar.gz\"\n",
    "config['MODEL_NAME'] = \"mbart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e22c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3  \n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=config[\"S3_MODEL\"],\n",
    "    role=role,\n",
    "    transformers_version='4.26',\n",
    "    pytorch_version='1.13',\n",
    "    py_version='py39',\n",
    ")\n",
    "\n",
    "endpoint_name = config['MODEL_NAME'].upper() + strftime(\"-%Y%m%d-%H%M%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e83455-19a1-4b0f-b3c8-c128e2fdef6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g4dn.4xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    ")\n",
    "\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80409ee-5176-4c04-b94c-dfb571331564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFacePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b8831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = HuggingFacePredictor(\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059a481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
