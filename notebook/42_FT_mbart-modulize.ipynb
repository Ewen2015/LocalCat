{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff786306-107d-46ce-96b2-0a3084f13680",
   "metadata": {},
   "source": [
    "# Fine Tune\n",
    "\n",
    "**Reference:** https://neptune.ai/blog/hugging-face-pre-trained-models-find-the-best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19593727-16be-4674-aa2a-f7f6351dd9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f782ce8-03b0-4ae9-a04d-98bf7a2329fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f96178-c280-42ba-9e5f-c77725f96319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd9ced-02ba-425d-860e-4086872d8cf0",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01a65d1-6e9a-4f75-8b6a-ebaa39a4d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"mbart-finetuned-cn-to-en-auto\"\n",
    "model_path = f\"../models/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc29578-9024-43ce-b50f-a12b5d2a7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c76fb4-b36e-4c38-ba0e-f8d90ff54039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5c1ec2-fea8-4129-ac4b-2b9517b2c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"开空调的情况下，续航掉的太快了，特别是冬天天气冷的时候，不开空调不行，天气一冻，续航就掉的更快\"\n",
    "\n",
    "# tokenizer.src_lang = 'zh'\n",
    "# tokenizer.tgt_lang = 'en'\n",
    "\n",
    "# tokenized_text = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "# print(tokenized_text)\n",
    "# print()\n",
    "\n",
    "# translation = model.generate(**tokenized_text)\n",
    "# print(translation)\n",
    "# print()\n",
    "\n",
    "# translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)\n",
    "# print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfad005-4e9c-41a9-9036-4295a82ba842",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2100a9c2-b0dd-4c25-8d3e-0272215f0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f997dad-da14-4023-8ae5-79c27be23edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_proc = \"../data/trans/PROC-NCVQS-2021-2023.csv\"\n",
    "file_sample = \"../data/trans/PROC_SAMPLE.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb242a9-46ce-449d-964a-2a7c2c7a658d",
   "metadata": {},
   "source": [
    "### Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2cf31a-7794-4b69-af41-c72a6a7ebbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(file_proc)\n",
    "\n",
    "# df.head(20).to_csv(file_sample, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0fe18a-a61d-45ea-bf13-b13520adedce",
   "metadata": {},
   "source": [
    "## Batch Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1a8da7-0d91-4d8a-819f-a4930b117930",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sample = \"../data/trans/PROC_SAMPLE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e85f159-926b-4c2a-af36-ebf297bfbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "770f27b8-2c53-4ffe-8527-d6792c6d2ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chinese</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第二排的舒适性不太理想，减震有点硬，平时有坎时感觉咣当一下，不是很舒服，选择舒适性</td>\n",
       "      <td>The comfort of the second row is not ideal, the shock absorption is a bit hard, and it feels awkward when there are bumps, which is not very comfortable, and I choose comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>减震硬，路况不好的地方不太舒服，选择舒适性（在路况不好，沟沟坎坎比较多时候，车内晃动大）</td>\n",
       "      <td>The shock absorption is hard, and riding under poor road conditions are not very comfortable. I choose comfort (when the road conditions are not good and there are many ridges and bumps, the inside of the car shakes a lot)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>车内的网络连接不稳定（自带的车联网，通过流量卡连接的互联网，有时使用中会突然没有网，在使用任何APP时都有发生几率，不知是什么原因）</td>\n",
       "      <td>The network connection in the car is unstable (the built-in car network, the Internet is connected through the data traffic card, sometimes there is no network during use, it might happen when using any APP, and I don’t know why)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>开空调时车内有潮气的味道，开热风冷风都会有，问了问，有人说是滤芯的气味，不是很重（新车，没有更换过空气滤波器）</td>\n",
       "      <td>There is a smell of moisture in the car when the AC is turned on both when hot and cold air is supplied in the car. When I asked, some repairmen said that it was the smell of the filter element, which was not very heavy (new car, the air filter has not been replaced)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第二排两侧的车门关门时声音咚咚的，声音很沉，感觉车门有点重，听上去没有质感，不是什么大问题，设计的问题</td>\n",
       "      <td>When the doors on both sides of the second row are closed, the thumping sound is very heavy. It doesn't feel good quality texture, not a big problem, a design issue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Chinese  \\\n",
       "0                           第二排的舒适性不太理想，减震有点硬，平时有坎时感觉咣当一下，不是很舒服，选择舒适性   \n",
       "1                        减震硬，路况不好的地方不太舒服，选择舒适性（在路况不好，沟沟坎坎比较多时候，车内晃动大）   \n",
       "2  车内的网络连接不稳定（自带的车联网，通过流量卡连接的互联网，有时使用中会突然没有网，在使用任何APP时都有发生几率，不知是什么原因）   \n",
       "3             开空调时车内有潮气的味道，开热风冷风都会有，问了问，有人说是滤芯的气味，不是很重（新车，没有更换过空气滤波器）   \n",
       "4                 第二排两侧的车门关门时声音咚咚的，声音很沉，感觉车门有点重，听上去没有质感，不是什么大问题，设计的问题   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       English  \n",
       "0                                                                                               The comfort of the second row is not ideal, the shock absorption is a bit hard, and it feels awkward when there are bumps, which is not very comfortable, and I choose comfort  \n",
       "1                                               The shock absorption is hard, and riding under poor road conditions are not very comfortable. I choose comfort (when the road conditions are not good and there are many ridges and bumps, the inside of the car shakes a lot)  \n",
       "2                                        The network connection in the car is unstable (the built-in car network, the Internet is connected through the data traffic card, sometimes there is no network during use, it might happen when using any APP, and I don’t know why)  \n",
       "3  There is a smell of moisture in the car when the AC is turned on both when hot and cold air is supplied in the car. When I asked, some repairmen said that it was the smell of the filter element, which was not very heavy (new car, the air filter has not been replaced)  \n",
       "4                                                                                                         When the doors on both sides of the second row are closed, the thumping sound is very heavy. It doesn't feel good quality texture, not a big problem, a design issue  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79553c7a-dc6f-491e-974e-6c53ee5b8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Translate import Translate\n",
    "\n",
    "trans = Translate(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45a2f8f1-7172-4fdd-883e-a337fde6c627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the case of turning on the air conditioner, the endurance mileage drops too fast, especially in winter when the weather is cold. If I don't turn on the air conditioner, the endurance mileage will drop faster, especially when the weather is cold in winter. If I don't turn on the air conditioner, the endurance mileage will drop faster when the weather is freezing.\n"
     ]
    }
   ],
   "source": [
    "text = \"开空调的情况下，续航掉的太快了，特别是冬天天气冷的时候，不开空调不行，天气一冻，续航就掉的更快\"\n",
    "print(trans.translator(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da7d2429-ab0c-4a84-83f2-dc96debe14d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = trans.translator_batch(df, col_tgt=\"Translation\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654cf7f-1640-45be-a84d-4cecf37118a7",
   "metadata": {},
   "source": [
    "## Fine-tune\n",
    "\n",
    "### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adafb203-7632-487b-b24c-d0292813fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f843e4d9-b0dc-4108-b98d-970d71847632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd86fcd1-ab07-4d9e-bc2b-af113cb1b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(df, col_src='Chinese', col_tgt='English', train_size=0.9):\n",
    "    \"\"\"\n",
    "    Generates a DatasetDict for machine translation from a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "    df: A pandas DataFrame containing the source and target language columns.\n",
    "    col_src: The name of the source language column (default: 'Chinese').\n",
    "    col_tgt: The name of the target language column (default: 'English').\n",
    "    train_size: The proportion of the data to use for training (default: 0.9).\n",
    "\n",
    "    Returns:\n",
    "    A DatasetDict containing the training, validation, and test datasets.\n",
    "    \"\"\"\n",
    "    df = df.assign(translation=df.apply(lambda row:{'zh': row['Chinese'], 'en': row['English']}, axis=1))\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(['index', 'Chinese', 'English'], axis=1, inplace=True)\n",
    "    \n",
    "    test_size = 1 - train_size\n",
    "    dataset = Dataset.from_pandas(df, split='train')\n",
    "    dataset = dataset.train_test_split(test_size=test_size)\n",
    "    testset = dataset['test'].train_test_split(test_size=0.5)\n",
    "    dataset = DatasetDict({\n",
    "        'train': dataset['train'],\n",
    "        'test': testset['test'],\n",
    "        'valid': testset['train']})\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6adc8653-34e6-4ec1-b037-3c2fe6cc8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.dataset = trans.generate_dataset(df, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27685fef-7d91-4f47-8058-471698221e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8ca35-a367-498b-92c3-cb8dcb75c62f",
   "metadata": {},
   "source": [
    "### Tokenize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa16cde-dc6b-4e9e-9caf-ca04bec1984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(self, max_length_input=512, max_length_target=512, prefix=''):\n",
    "    self.max_length_input = max_length_input\n",
    "    self.max_length_target = max_length_target\n",
    "    \n",
    "    def tokenizer(case):\n",
    "        inputs = [prefix + i[self.src_lang] for i in case[\"translation\"]]\n",
    "        targets = [i[self.tgt_lang] for i in case[\"translation\"]]\n",
    "\n",
    "        model_inputs = self.tokenizer(inputs, max_length=self.max_length_input, truncation=True)\n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "            labels = self.tokenizer(targets, max_length=self.max_length_target, truncation=True)\n",
    "\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "    \n",
    "    tokenized_datasets = self.dataset.map(tokenizer, batched=True)\n",
    "    return tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d517fec1-2671-44b5-bf50-27e17f0384e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9e218cc5fe4e7a84fc89eafc236297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e70632180a24e3abd6a208e380b8889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dd60999f004e01b88cd8e705e84a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = trans.tokenize_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ce4f33e-887e-4185-8149-fdec697042b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be874b8-8fbf-4224-bdcd-6ab56d7b4ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "875f5bd5-0a65-4b8b-ba94-559bdde3e0bc",
   "metadata": {},
   "source": [
    "## Train and Fine-tune the Model\n",
    "\n",
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be0f2f1d-e398-48e7-a3f2-b355b4163fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67690c66-e8b2-4c56-9dd7-13c08a6ab649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(self, \n",
    "             df, rain_size=0.9, col_src='Chinese', col_tgt='English', \n",
    "             max_length_input=512, max_length_target=512, prefix='',\n",
    "             model_path=\"model\", batch_size=4):\n",
    "    self.dataset = self.generate_dataset(df, \n",
    "                                         train_size=train_size, \n",
    "                                         col_src=col_src, col_tgt=col_tgt)\n",
    "    self.tokenized_dataset = self.tokenize_dataset(max_length_input=max_length_input, \n",
    "                                                    max_length_target=max_length_input, \n",
    "                                                    prefix=prefix)\n",
    "    self.args = Seq2SeqTrainingArguments(\n",
    "       output_dir=model_path,\n",
    "       evaluation_strategy=\"epoch\",\n",
    "       learning_rate=2e-5,\n",
    "       per_device_train_batch_size=batch_size,\n",
    "       per_device_eval_batch_size=batch_size,\n",
    "       weight_decay=0.01,\n",
    "       save_total_limit=3,\n",
    "       num_train_epochs=1,\n",
    "       predict_with_generate=True,\n",
    "    )\n",
    "    \n",
    "    self.data_collator = DataCollatorForSeq2Seq(tokenizer=self.tokenizer, model=self.model)\n",
    "    \n",
    "    metric = evaluate.load(\"sacrebleu\")\n",
    "    meteor = evaluate.load('meteor')\n",
    "    \n",
    "    self.trainer = Seq2SeqTrainer(\n",
    "        model=self.model,\n",
    "        args=self.args,\n",
    "        train_dataset=self.tokenized_dataset['train'],\n",
    "        eval_dataset=self.tokenized_dataset['valid'],\n",
    "        data_collator=self.data_collator,\n",
    "        tokenizer=self.tokenizer,\n",
    "        compute_metrics=self.compute_metrics,\n",
    "    )\n",
    "    \n",
    "    self.trainer.train()\n",
    "    self.trainer.save_model()\n",
    "    \n",
    "    self.eval_result = self.trainer.evaluate(self.tokenized_dataset['test'])\n",
    "    print(self.eval_result)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa560d6-c87f-4f58-b08b-dc684747ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"mbart-finetuned-cn-to-en-auto-sample\"\n",
    "model_path = f\"../models/{model_name}\"\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "   output_dir=model_path,\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=batch_size,\n",
    "   per_device_eval_batch_size=batch_size,\n",
    "   weight_decay=0.01,\n",
    "   save_total_limit=3,\n",
    "   num_train_epochs=1,\n",
    "   predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b6757-3c1b-49ca-8c97-7482310b59eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model) # default setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3df329-c8eb-42eb-b5e2-770c6fc7b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")\n",
    "meteor = evaluate.load('meteor')\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result = {'bleu' : result['score']}\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result[\"meteor\"] = meteor_result[\"meteor\"]\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2d2be-dd2d-4745-acb8-dccc4fc6e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e884133-9948-432d-aa21-f4b2e3b39dfc",
   "metadata": {},
   "source": [
    "### Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60c32c-46da-4e91-963b-6cb9dc5766ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c361087-290a-4194-86a9-102c40f3683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8129f2-bd08-401d-8e33-2289c1af506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008df14-dc52-423d-a7ee-f0d0c90d1f9e",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85daf29f-7894-4030-8140-a800a4b9bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d4526-74a3-47f9-acbb-5c59e470365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"开空调的情况下，续航掉的太快了，特别是冬天天气冷的时候，不开空调不行，天气一冻，续航就掉的更快\"\n",
    "\n",
    "tokenizer.src_lang = 'zh_CN'\n",
    "tokenizer.tgt_lang = 'en_XX'\n",
    "\n",
    "encoded = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "model = model.to(device)\n",
    "generated_tokens = model.generate(**encoded)\n",
    "decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf7399-0978-49eb-b8ac-7413f0f4605a",
   "metadata": {},
   "source": [
    "> \"开空调的情况下，续航掉的太快了，特别是冬天天气冷的时候，不开空调不行，天气一冻，续航就掉的更快\"\n",
    "\n",
    "> **no fine-tuning** 'If the air conditioner is on, the flight resumes too quickly, especially in winter when the weather is cold. If the air conditioner is not on, the flight resumes faster as soon as the weather is cold'\n",
    "\n",
    "> **fine-tuned with data of 2023** If you turn on the air conditioner, the electric range is too fast to fall off, especially in winter when the weather is cold and cold, it is not possible to not turn on the air conditioner without turning on the air conditioner, as the weather freezes and freezes, the electric range will fall off faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b085e48-e3b1-477a-a9c2-369d1da4673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    encoded = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "    generated_tokens = model.generate(**encoded)\n",
    "    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728828b-00b7-4492-a34b-3c5f509acf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset['test']['translation'][:5]:\n",
    "    print(\"=\"*30)\n",
    "    print(i['zh'])\n",
    "    print(i['en'])\n",
    "    print(\"=\"*10)\n",
    "    result = translate(i['zh'])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39486ca4-9b68-4d38-ac28-772bd423091c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
