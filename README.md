# LocalCat

![PyPI version](https://badge.fury.io/py/localcat.svg)
![Documentation Status](https://readthedocs.org/projects/localcat/badge/?version=latest)
![Python Versions](https://img.shields.io/pypi/pyversions/localcat.svg)
![GitHub](https://img.shields.io/github/license/ewen2015/localcat)

**LocalCat** enables users to deploy large language models (LLMs) from Hugging Face to local environments, such as personal laptops or cloud platforms like AWS.

## Tasks
### Translation
LocalCat offers user-friendly tools for translation tasks, allowing the translator to be deployed as an endpoint or for batch processing of dataframes. Additionally, it provides fine-tuning capabilities for local deployment. 

LocalCat's intuitive interface and efficient processing make it a valuable asset for any translation project. With its advanced features and customizable options, users can easily tailor their translations to meet specific requirements and ensure accuracy. Whether you're working on a small document or a large dataset, LocalCat has the tools you need to streamline the translation process and achieve high-quality results.

### Chat
#### Retrieval Augmented Generation (RAG)
Localcat specializes in open-source LLMs and RAG for local deployment. Localcat offers a wide range of solutions for local deployment, including custom configurations and expert support for seamless integration. With a focus on user-friendly interfaces and scalable performance, Localcat is the ideal choice for organizations looking to optimize their LLMs and RAG processes.

## Install
```python
pip install localcat
```